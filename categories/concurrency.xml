<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Virtual World (Concurrency)</title><link>http://www.jiaqili.me/</link><description></description><atom:link href="http://www.jiaqili.me/categories/concurrency.xml" type="application/rss+xml" rel="self"></atom:link><language>zh_cn</language><lastBuildDate>Mon, 28 Dec 2015 08:47:54 GMT</lastBuildDate><generator>https://getnikola.com/</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>《Java并发实践》总结二：结构化并发应用程序</title><link>http://www.jiaqili.me/posts/java-concurrency-2/</link><dc:creator>Jiaqi Li</dc:creator><description>&lt;div&gt;&lt;h2&gt;1 Executor框架&lt;/h2&gt;
&lt;p&gt;任务是一个逻辑执行单元，而线程是使任务异步执行的机制。串行执行会降低响应性和吞吐量；每个任务都分配一个线程会造成很大开销也不利于资源管理。&lt;/p&gt;
&lt;p&gt;该框架包括一个灵活的线程池，提供了不同类型的任务的执行策略，并将任务提交过程和执行过程解耦，用Runnable来表示一个任务。此外Executor框架还提供了对生命周期的支持，以及统计信息的收集、应用程序管理机制和性能监视等机制。&lt;/p&gt;
&lt;p&gt;执行策略定义了任务执行的"what, where, when, how"等方面。比如在什么线程中执行任务，按什么顺序执行，多少个任务可以并发执行，队列了可以有多少个任务在等待，在任务执行之前和之后应该进行哪些操作，如果要拒绝一个任务，应该选择哪一个？等等&lt;/p&gt;
&lt;p&gt;当需要灵活的执行策略时，用Executor框架来代替手动编写Thread。&lt;/p&gt;
&lt;h3&gt;1.1 Executor&lt;/h3&gt;
&lt;p&gt;Executor接口如下，它是java.util.concurrent异步执行框架的基础。&lt;/p&gt;
&lt;pre class="code literal-block"&gt;public interface Executor{
    void execute(Runnable command);
}
&lt;/pre&gt;


&lt;p&gt;Executor基于生产者消费者模式，提交任务的线程相当于生产者，执行任务的线程相当于消费者&lt;/p&gt;
&lt;h3&gt;1.2 ExecutorService&lt;/h3&gt;
&lt;p&gt;ExecutorService接口扩展了Executor，提供了生命周期的支持和提交任务的方法。ThreadPoolExecutor实现了这个接口，但一般通过Executors的工厂方法来创建和配置线程池。&lt;/p&gt;
&lt;h4&gt;1.2.1 线程池&lt;/h4&gt;
&lt;p&gt;线程池与任务队列密切相关，工作线程从任务队列里获取一个任务，执行完成任务，返回线程池，等待下一个任务。&lt;/p&gt;
&lt;p&gt;线程池通过重用现有的线程而不是对每个任务创建新的线程来，1. 减少线程创建和销毁时的开销; 2. 当请求到达时，工作线程通常已经存在，提高了响应性。&lt;/p&gt;
&lt;p&gt;Executors的工厂方法可以配置很多种线程池，比如
1. newFixedThreadPool: 固定大小的线程池，每提交一个任务就创建一个线程，直到达到指定的最大数量；
2. newCachedThreadPool: 一个可缓存的线程池，当线程池规模超过需要处理的任务数量时，将回收空闲线程，当需要增加时，将添加新的线程，规模不存在限制;
3. newSingleThreadExecutor: 创建单线程的Executor，确保任务依照队列中的顺序执行；
4. NewScheduledThreadPool: 固定长度的线程池，通过延时或定时的方法执行任务。&lt;/p&gt;
&lt;h4&gt;1.2.2 生命周期支持&lt;/h4&gt;
&lt;p&gt;因为向Executor提交的任务是异步执行，有一些可能已经完成，一些在运行，一些在等待，所以关闭ExecutorService提供了一些方法来关闭Executor。&lt;/p&gt;
&lt;p&gt;ExecutorService有三种状态，运行、关闭和已终止。在创建后它即处于运行状态。shutdown方法执行后，它将不再接受新的任务，同时等待已提交的（包括还在等待的）任务执行完成；shudownNow方法将尝试取消所有运行的任务，不再启动等待的任务。ExecutorService关闭后，提交的任务将由Rejected execution handler处理，它会抛弃任务，或者抛出一个RejectedExecutionException。等所有任务都完成后，ExecutorService进入已停止状态，可以调用awaitTermination来等待ExecutorService停止，或者通过isTerminated来轮训。&lt;/p&gt;
&lt;p&gt;比如下面的一个web服务器：&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="n"&gt;LifecycleWebServer&lt;/span&gt; {
    &lt;span class="n"&gt;private&lt;/span&gt; &lt;span class="n"&gt;final&lt;/span&gt; &lt;span class="n"&gt;ExecutorService&lt;/span&gt; &lt;span class="n"&gt;exec&lt;/span&gt; = ...;

    &lt;span class="n"&gt;public&lt;/span&gt; &lt;span class="nb"&gt;void&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt;() &lt;span class="n"&gt;throws&lt;/span&gt; &lt;span class="n"&gt;IOException&lt;/span&gt; {
        &lt;span class="n"&gt;ServerSocket&lt;/span&gt; &lt;span class="n"&gt;socket&lt;/span&gt; = &lt;span class="nb"&gt;new&lt;/span&gt; &lt;span class="n"&gt;ServerSocket&lt;/span&gt;(&lt;span class="mi"&gt;80&lt;/span&gt;);
        &lt;span class="k"&gt;while&lt;/span&gt; (!&lt;span class="n"&gt;exec&lt;/span&gt;.&lt;span class="n"&gt;isShutdown&lt;/span&gt;()) {
            &lt;span class="k"&gt;try&lt;/span&gt; {
                &lt;span class="n"&gt;final&lt;/span&gt; &lt;span class="n"&gt;Socket&lt;/span&gt; &lt;span class="n"&gt;conn&lt;/span&gt; = &lt;span class="n"&gt;socket&lt;/span&gt;.&lt;span class="n"&gt;accept&lt;/span&gt;();
                &lt;span class="n"&gt;exec&lt;/span&gt;.&lt;span class="n"&gt;execute&lt;/span&gt;(&lt;span class="nb"&gt;new&lt;/span&gt; &lt;span class="n"&gt;Runnable&lt;/span&gt;() {
                    &lt;span class="n"&gt;public&lt;/span&gt; &lt;span class="nb"&gt;void&lt;/span&gt; &lt;span class="nb"&gt;run&lt;/span&gt;() { &lt;span class="n"&gt;handleRequest&lt;/span&gt;(&lt;span class="n"&gt;conn&lt;/span&gt;); }
                });
             } &lt;span class="n"&gt;catch&lt;/span&gt; (&lt;span class="n"&gt;RejectedExecutionException&lt;/span&gt; &lt;span class="nb"&gt;e&lt;/span&gt;) {
                &lt;span class="k"&gt;if&lt;/span&gt; (!&lt;span class="n"&gt;exec&lt;/span&gt;.&lt;span class="n"&gt;isShutdown&lt;/span&gt;())
                    &lt;span class="nb"&gt;log&lt;/span&gt;(&lt;span class="s"&gt;"task submission rejected"&lt;/span&gt;, &lt;span class="nb"&gt;e&lt;/span&gt;);
             }
        }
    }

    &lt;span class="n"&gt;public&lt;/span&gt; &lt;span class="nb"&gt;void&lt;/span&gt; &lt;span class="n"&gt;stop&lt;/span&gt;() { &lt;span class="n"&gt;exec&lt;/span&gt;.&lt;span class="n"&gt;shutdown&lt;/span&gt;(); }

    &lt;span class="nb"&gt;void&lt;/span&gt; &lt;span class="n"&gt;handleRequest&lt;/span&gt;(&lt;span class="n"&gt;Socket&lt;/span&gt; &lt;span class="n"&gt;connection&lt;/span&gt;) {
        &lt;span class="n"&gt;Request&lt;/span&gt; &lt;span class="n"&gt;req&lt;/span&gt; = &lt;span class="n"&gt;readRequest&lt;/span&gt;(&lt;span class="n"&gt;connection&lt;/span&gt;);
        &lt;span class="k"&gt;if&lt;/span&gt; (&lt;span class="n"&gt;isShutdownRequest&lt;/span&gt;(&lt;span class="n"&gt;req&lt;/span&gt;))
            &lt;span class="n"&gt;stop&lt;/span&gt;();
        &lt;span class="k"&gt;else&lt;/span&gt;
            &lt;span class="n"&gt;dispatchRequest&lt;/span&gt;(&lt;span class="n"&gt;req&lt;/span&gt;);
    }
}
&lt;/pre&gt;


&lt;h4&gt;1.2.3 任务提交，完成和取消&lt;/h4&gt;
&lt;p&gt;Exectuor接口的execute方法只能接受Runnable，Runnable没有返回值。而扩展了的ExecutorService添加了submit方法允许提交Callable，Callable的call方法将返回一个值或者抛出异常。&lt;/p&gt;
&lt;p&gt;Executor执行的任务有4个生命周期，创建，提交，开始和完成。Future表示一个任务的生命周期。将一个Runnable或者Callable通过submit方法提交给ExecutorService后返回一个Future，这个Future可以用来判断任务是否完成或者取消，以及获取任务的结果或者取消任务。&lt;/p&gt;
&lt;p&gt;将Runnable或者Callable提交到ExecutorService的过程包括了一个安全地将Runnable或者Callable从提交线程发布到执行线程的过程；设置Future结果的过程也包括了，将计算结果从执行线程发布到任何通过get获得它的线程。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Future的get方法：如果任务已经完成，将立即返回结果或抛出异常；如果没有完成，get将阻塞，如果设置了超时参数，那么在指定时间内仍旧没有完成将抛出TimeoutException，然后再通过Future来取消任务；如果计算过程中抛出异常，该异常被封装成ExecutionException由get重新抛出，通过getCause来获取最初的异常；如果任务被取消，将抛出CancellationException。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用CompletionService：提交到ExecutorService的任务返回一个Future引用，要知道是否完成任务，需要一个个检查任务；而实现了CompletionService结合了Executor和一个BlockingQueue，把完成的Future&lt;v&gt;放入到一个BlockingQueue，这样就可以只要不断地从一个队列中获取完成的任务就可以了。&lt;/v&gt;&lt;/p&gt;
&lt;p&gt;ExecutorCompletionService实现了CompletionSetrvice接口，它的构造函数需要一个Executor，并创建一个BlockingQueue来保存计算完的结果。当提交任务时，该任务会被包装为QueueingFuture（一个Future的子类），然后改写了该子类的done方法，当计算完后，FutureTask的done方法会被调用，结果就被放到了BlockingQueue中国。&lt;/p&gt;
&lt;p&gt;摘自Stackoverflow：
ExecutorService = incoming queue + worker threads
CompletionService = incoming queue + worker threads + output queue&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用invokeAll：如果有一组任务，一般的做法是一个个提交，获取n个Future，然后一个个获取结果。如果使用invokeAll，它需要一组任务并返回一组Future。它按照参数中任务结合的顺序添加任务，并将返回Future全部添加到返回的集合里。当所有任务都执行完毕后，或者调用线程被中断，或者超时，invokeAll将返回，超时未完成的任务会被取消。所以invokeAll返回的任务要么是已经完成的，要么是被取消的。注意：调用invokeAll本身会导致阻塞，直到所有任务结束或超时，这和CompletionService是不同的。通过后者可以按照任务完成的顺序从BlockingQueue中获取完成的任务。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;1.3 ScheduledExecutorService&lt;/h3&gt;
&lt;p&gt;该接口继承了ExecutorService，用于定时或者延时的任务。ScheduledThreadPoolExecutor实现了这个接口，并继承了TreadPoolExecutor。可以通过上文的Executors的工厂方法newScheduledThreadPool来创建该对象或者直接用它的构造函数。&lt;/p&gt;
&lt;p&gt;应该用它来替代Timer类，因为在定时的精准性以及异常处理上，ScheduledThreadPoolExecutor更好。&lt;/p&gt;
&lt;h3&gt;1.4 Executor框架的UML图&lt;/h3&gt;
&lt;p&gt;Image from http://www.uml-diagrams.org/java-7-concurrent-uml-class-diagram-example.html&lt;/p&gt;
&lt;p&gt;&lt;img alt="ExecutorUML.png" src="http://www.uml-diagrams.org/examples/java-7-concurrent-executors-uml-class-diagram-example.png" title=" "&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(未完待续)&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;</description><category>Concurrency</category><category>Java</category><guid>http://www.jiaqili.me/posts/java-concurrency-2/</guid><pubDate>Mon, 28 Dec 2015 08:10:20 GMT</pubDate></item><item><title>《Java并发实践》总结一：线程安全基础知识</title><link>http://www.jiaqili.me/posts/java-concurrency-1/</link><dc:creator>Jiaqi Li</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;em&gt;本文是《Java并发编程实战》的第2-3,5,13,15章的读书笔记，内容总结。书中所介绍的非阻塞的并发算法和数据结构比较粗略，仅限于特性和应用介绍，很少有具体实现，这里也做简单记录。更多的内容可以参考《多处理器编程的艺术》第一修订版以及https://www.cs.ox.ac.uk/teaching/materials15-16/cads。以后单独总结。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;编写线程安全代码的核心在于对共享的可变的状态的访问操作进行管理。状态指储存在实例或静态域中的数据；共享表示变量可被多个线程同时访问；可变意味着变量值在其生命周期内可以发生变化。&lt;/p&gt;
&lt;p&gt;当多个线程访问某个可变的状态变量，并且至少有一个写线程时，需要采用同步机制。Java的同步机制，主要是Synchronized关键词，volatile变量，显示锁(Explicit Lock)，以及原子变量(Atomic Variables)。否则，要么该变量不在多线程中共享，要么将其设置为不可变。&lt;/p&gt;
&lt;h2&gt;1 线程安全性&lt;/h2&gt;
&lt;p&gt;线程安全的程序并不一定完全由线程安全类构成，完全由线程安全类构成的程序也未必是线程安全的。线程安全性只与状态相关，只能用于封装其状态的整个代码，比如线程安全类，或者线程安全程序。&lt;/p&gt;
&lt;p&gt;定义：当多个线程访问某个类时，不管运行时环境采取何种调度方式或者这些线程将如何交替执行，并且在主调代码中不需要任何额外的同步或协同，这个类都能表现出正确的行为，那么这个类时线程安全的。&lt;/p&gt;
&lt;p&gt;线程安全类中封装了必要的同步机制，因此客户端无需进一步采取同步措施。一个无状态的类肯定是线程安全的。&lt;/p&gt;
&lt;h3&gt;1.1 竞态条件&lt;/h3&gt;
&lt;p&gt;竞态条件是指某个计算结果的正确性取决于多个线程交替执行的顺序。造成不正确性的原因一般是基于失效的观察结果做出的判断。&lt;/p&gt;
&lt;h3&gt;1.2 重排序&lt;/h3&gt;
&lt;p&gt;在没有同步的情况下，编译器、处理器和运行时都可能对操作的执行顺序进行调整。&lt;/p&gt;
&lt;h3&gt;1.3 发布与逸出&lt;/h3&gt;
&lt;p&gt;发布是指对象能够在当前作用域之外的代码中使用，而逸出是指一个不该被发布的对象被发布。以下几种情况：
1. 将对象引用保存到公有变量中；
2. 发布某个对象时，该对象包含其他对象，可能会间接发布这些对象，比如一个发布一个集合；
3. 发布某个对象时，该对象非私有域引用的所有对象以及非私有方法可达的对象也会被发布；
4. this逸出：在构造函数返回前，别的对象获取了this引用。通常发生在在构造函数中启动线程，或者发布内部类，因为两者都包含this引用。this逸出会导致一个未构造完的类被发布，这种对象被称为是不正确的构造，应该避免在构造过程中导致this逸出。&lt;/p&gt;
&lt;h3&gt;1.4 原子性&lt;/h3&gt;
&lt;p&gt;如果一个操作具有原子性，那么对于访问同一个状态的所有操作（包括自身）来说，这个操作是以原子（即不可分割的）方式执行的。比如，对于线程A的任意一个指令来说，线程B执行原子操作x时，B要么已经执行完了x，要么完全没有执行x。同步机制可以确保操作的原子性。比如原子变量，参见java.util.concurrent.atomic。&lt;/p&gt;
&lt;h3&gt;1.5 可见性&lt;/h3&gt;
&lt;p&gt;一个线程修改了对象状态以后，其他线程能够看到发生的状态变化。同步机制可以确保可见性。当线程在没有同步的情况下读取变量，可能会得到失效数据。其中大部分变量的这个值至少由之前的某个线程设置，而不是随机值，即最低安全性；但是非volatile的double和long因为是64位的，可能读到高32位和低32位不一致的值。&lt;/p&gt;
&lt;h2&gt;2 各种实现线程安全的方法&lt;/h2&gt;
&lt;h3&gt;2.1 阻塞同步机制：内置锁（同步代码块/方法）&lt;/h3&gt;
&lt;p&gt;Synchronized Block 包括一个作为锁的对象引用（静态的synchronized方法以Class对象作为锁），一个作为由这个锁保护的代码块。每个对象都包含一个可以被用作同步的锁，这些被称为内置锁或者Monitor Lock。&lt;/p&gt;
&lt;p&gt;内置锁相当于一种互斥体，只能最多由一个线程持有这种锁，相当于这个锁保护的代码块以原子的形式被执行。任何其他请求这个锁的代码，都将被阻塞直到锁可用。&lt;/p&gt;
&lt;p&gt;如果某个线程想获得一个由它自己持有的内置锁，那么会成功，因为内置锁是可重入的。一种可重入锁的实现方式是每个锁关联一个计数器和持有者线程，当计数器为0时，即为解锁状态，当一个线程请求一个未被持有的锁时，JVM记下该持有者，计数器置为1，当同一个线程再次请求该锁时，计数器递增，线程退出同步代码块时，计数器递减。&lt;/p&gt;
&lt;p&gt;每一个共享的可变变量都应该只由一个锁来保护。对象的内置锁和其状态之间没有关联，当获取与对象关联的锁时，并不能阻止其他线程访问该对象，只能阻止其他线程获取同一个锁。对于包含多个变量的不变量，其所有变量必须由同一个锁保护。&lt;/p&gt;
&lt;p&gt;访问共享状态的复合操作，比如递增，都必须具有原子性以避免竞态条件。同步可以避免竞态条件，但对于每个方法都加同步关键字，1. 会出现liveness和性能问题; 2. 同步方法的复合并不一定是原子的。&lt;/p&gt;
&lt;p&gt;同步代码块大小要合理，要权衡各种设计需求，比如安全性（必须满足），简单性（不要将同步代码块拆分地过细）和并发性（对尽可能短的代码进行同步）。如果持有锁的时间过长，会带来liveness和性能问题，特别是大量计算和IO时不要持有锁。&lt;/p&gt;
&lt;h3&gt;2.2 阻塞同步机制：volatile变量&lt;/h3&gt;
&lt;p&gt;volatile是一种比Synchronized更轻量级的同步机制，也算是一种内置锁。&lt;/p&gt;
&lt;p&gt;变量什么为volatile后，涉及该变量的操作不会与其他内存操作一起重排序。&lt;/p&gt;
&lt;p&gt;volatile变量不会被缓存在寄存器或其他对其他处理器不可见的地方，读取volatile变量时总会返回最新值。&lt;/p&gt;
&lt;p&gt;仅在以下情况下建议使用：确保它自身状态或者引用对象的可见性，标记一些重要的程序生命周期（比如中断某个循环的条件）。&lt;/p&gt;
&lt;p&gt;volatile不能确保原子性，比如它们的变量自增操作不是原子性的，只能保证可见性；而加锁机制可以确保原子性和可见性。&lt;/p&gt;
&lt;h3&gt;2.3 阻塞同步机制：显示锁&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;本节也摘抄/参考了java.util.concurrent.locks文档&lt;/em&gt;&lt;/p&gt;
&lt;h4&gt;2.3.1 Lock接口&lt;/h4&gt;
&lt;p&gt;Synchronized内置锁提供原子性和可见性，但是无法中断一个等待获取锁的线程，也无法实现非阻塞的加锁机制，而Lock还能同时提供可定时，可轮训，可中断的锁获取操作，它的实现ReentrantLock和ReentrantReadWriteLock还提供公平性的锁获取选项。&lt;/p&gt;
&lt;p&gt;所有的加锁方式是显示的，意味着没有在finally块中显示的unlock是很危险的。&lt;/p&gt;
&lt;p&gt;选择何种锁？应该避免混合使用。建议仅当内置锁不能满足要求的时候，才考虑显示锁。&lt;/p&gt;
&lt;pre class="code literal-block"&gt;public interface Lock{
    void lock();
    void lockInterruptibly() throws InterruptedException;
    Boolean tryLock();
    Boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException;
    void unlock();
    Condition newCondition();
}
&lt;/pre&gt;


&lt;p&gt;显示锁的标准使用方式&lt;/p&gt;
&lt;pre class="code literal-block"&gt;Lock l = new SomeLock();
//…
l.lock();
try{…}
finally{
    l.unlock();
}
&lt;/pre&gt;


&lt;h4&gt;2.3.2 锁的获取&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;轮训获取锁：通过一个循环配合tryLock()来不断尝试获取锁，tryLock()是非阻塞的锁获取操作，它立即返回是否成功获取锁的boolean。注意如果不能获取到所有的锁，应释放已获得的锁，然后重新尝试获取全部的锁；&lt;/li&gt;
&lt;li&gt;可中断地获取锁：lockInterruptibly() 在等待获取锁的过程中可接受中断信号；&lt;/li&gt;
&lt;li&gt;时间限制锁：使用带参数的tryLock，线程将等待指定的时间。如果获取到锁，或者被中断，或者超时，函数返回；&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;2.3.3 ReentrantLock&lt;/h4&gt;
&lt;p&gt;重入锁的可以构造为公平的或者非公平的。默认构造函数生成的是非公平的锁。对于公平的重入锁，如果有另一个线程持有锁，或者有其他线程在队里中等待锁，新发出请求的线程将被放入队里中等待；对于非公平的重入锁，只有当某个线程持有锁时才，新线程才进入等待队列。注意，不带参数的tryLock()会无视公平性设置。&lt;/p&gt;
&lt;p&gt;当然重入锁顾名思义，还允许当前线程重复获取锁。&lt;/p&gt;
&lt;p&gt;非公平的锁其吞吐量一般比公平的锁更高，因为在上一个线程释放锁恢复下一个线程，到这个线程真正开始运行之间有延迟，期间非公平锁允许后来的线程抢占锁，这可能造成在线程还没完全恢复的期间，另一个线程已经完成获取锁到释放锁的全过程。&lt;/p&gt;
&lt;p&gt;当锁持有时间较长或者锁被请求的间隔时间较长时，应该使用公平锁。&lt;/p&gt;
&lt;h4&gt;2.3.4 ReadWriteLock接口&lt;/h4&gt;
&lt;pre class="code literal-block"&gt;public interface ReadWriteLock{
    Lock readLock();
    Lock writeLock();
}
&lt;/pre&gt;


&lt;p&gt;读写锁的目的是允许多个读线程同时持有锁，提高读操作的并发。文档要求所有实现读写锁接口的类都保证可见性。&lt;/p&gt;
&lt;p&gt;实现一个读写锁时需要考虑以下方面：
1. 当写线程释放write lock，并且还有读线程和写线程同时等待时，应该优先允许读线程还是写线程？常见的偏好是写线程，因为写操作期望来说比较短而且不常见；偏好读操作不太常见，因为如果读取线程频繁并且时间较长的话，可能导致一个写线程较长的延迟。或者也可以实现为公平的，即先到先得的策略；
2. 当一个读线程持有锁并且有写线程等待时，新的读线程能否获取到锁？如果允许读线程这时候进入，可以导致写线程无限期地推迟，如果偏好写线程将减少潜在的并发；
3. 是否可重入？一个持有write lock的线程能否再次获取write lock?是否可以同时获取一个read lock?
4. 写线程是否可降级为读线程，在不释放其write lock的前提下？读线程是否可以优先于其他等待的写线程升级为写线程?&lt;/p&gt;
&lt;h4&gt;2.3.5 ReentrantReadWriteLock&lt;/h4&gt;
&lt;p&gt;允许构造为公平的或者非公平的锁。&lt;/p&gt;
&lt;p&gt;和重入锁一样，重入读写锁允许重入，但是非重入读线程必须等待所有write lock被当前的写线程释放才可能进入，这是它的重入限制。&lt;/p&gt;
&lt;p&gt;允许写线程降级：当一个线程获取write lock后，它可以再获取read lock，然后释放write lock。但是不允许一个读线程升级。&lt;/p&gt;
&lt;p&gt;对于非公平的可重入读写锁，只要符合重入限制，读线程和写线程获取锁的顺序是不确定的。&lt;/p&gt;
&lt;p&gt;对于公平的可重入读写锁，获取锁的顺序大体上取决于等待的时间。当锁被释放时，等待时间最长的一组读线程，或等待时间最长的一个写线程会得到锁；对于非重入的读线程，如果当前持有锁的是写线程，或者有写线程等待，那么该线程将等待，直到当前等待时间最长的写线程获取并释放锁以后才能获取锁。不过如果当前等待的写线程放弃等待，造成该读线程成为等待队列里等待时间最长的线程，并且当前没有write lock被持有，那么该读线程被允许获取read lock；对于非重入的写线程，必须等待到没有read lock或者write lock被持有才能进入。&lt;/p&gt;
&lt;p&gt;同样地，不带参数的tryLock会无视公平性。&lt;/p&gt;
&lt;h4&gt;2.3.6 使用哪种显示锁&lt;/h4&gt;
&lt;p&gt;读取为主的数据结构应使用读写锁，其它情况下应该使用重入锁，但是可能非阻塞的数据结构性能会更好。&lt;/p&gt;
&lt;h3&gt;2.4 原子变量与非阻塞同步机制&lt;/h3&gt;
&lt;p&gt;目前并发算法领域的研究方向是用底层原子机器指令，比如CAS，代替锁来实现数据一致性的非阻塞算法。非阻塞算法设计和验证上非常复杂，但是多个线程出现竞争时不会出现阻塞，能进行细粒度的协调，并且能极大减少开销。此外，通过CAS操作实现的Java原子类本身也提供了类似volatile的可见性，还支持原子操作。&lt;/p&gt;
&lt;h4&gt;2.4.1 锁的劣势&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;挂起和回复线程存在很大的开销，特别是对于细粒度的操作；&lt;/li&gt;
&lt;li&gt;即使volatile不需要上下文切换和线程调度，并且保证可见性，但是它不能保证原子的复合操作，比如自增；&lt;/li&gt;
&lt;li&gt;线程等待锁时不能做其他的事情，一旦持有锁的线程永久阻塞，其他等待该锁的线程必须一致等下去。如果被阻塞的线程优先级高，持有锁的线程优先级低，则造成了优先级反转。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;2.4.2 受硬件支持的Compare-and-Set(CAS)操作&lt;/h4&gt;
&lt;p&gt;compareAndSet(variable, expectedValue, newValue);&lt;/p&gt;
&lt;p&gt;Variable: 需要读写的内存位置
expectedValue：期望的该内存位置保存的值
newValue：希望更新的值&lt;/p&gt;
&lt;p&gt;CAS通过原子的方式执行以下操作，读取variable的值，和expectedValue进行比较，一致则将variable更新为newValue，不一致则不更新，无论一致与否都返回variable原有的值。&lt;/p&gt;
&lt;p&gt;CAS是实现其他非阻塞数据结构的基础构件，它不会造成更新失败的线程的阻塞，而是仅仅知道它更新失败，可以再次尝试。&lt;/p&gt;
&lt;p&gt;Java.util.concurrent.aromic包中的类是基于硬件CAS操作的实现。&lt;/p&gt;
&lt;h4&gt;2.4.3 Atomic类&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;粒度比锁细，量级更轻，可用于实现高性能的并发代码；&lt;/li&gt;
&lt;li&gt;相比于使用锁的算法，使用原子类的算法更不易出现延迟，如遇竞争，更容易回复；&lt;/li&gt;
&lt;li&gt;因为它利用硬件的支持，在竞争的情况下能提供更高的可伸缩性。&lt;/li&gt;
&lt;li&gt;原子类可以作为一种更好的volatile变量&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;常用的原子类比如标量类的AtomicInteger, AtomicLong, AtomicBoolean以及AtomicReference，还有支持Integer，Long和Reference的数组类。&lt;/p&gt;
&lt;p&gt;AtomicInteger使用get和set方法作为访问值的接口，并提供一个compareAndSet的读改写操作，还有递增、添加、递减等操作。&lt;/p&gt;
&lt;h4&gt;2.4.4 非阻塞算法（非阻塞栈作为例子）&lt;/h4&gt;
&lt;p&gt;非阻塞算法：一个线程失败或挂起不会导致其他线程也失败或者挂起。
无锁算法：算法的每个步骤中都存在某个线程能够继续执行下去。&lt;/p&gt;
&lt;p&gt;如果算法中仅用CAS作为协调线程之间的操作，并能正确的实现，那么它是一种非阻塞的无锁算法。&lt;/p&gt;
&lt;p&gt;常见的数据结构都可以实现为非阻塞算法，包括栈、队列、散列表等。以下摘抄书中的栈的算法：&lt;/p&gt;
&lt;pre class="code literal-block"&gt;public class ConcurrentStack &amp;lt;E&amp;gt; {
    AtomicReference&amp;lt;Node&amp;lt;E&amp;gt;&amp;gt; top = new AtomicReference&amp;lt;Node&amp;lt;E&amp;gt;&amp;gt;();
    public void push(E item) {
        Node&amp;lt;E&amp;gt; newHead = new Node&amp;lt;E&amp;gt;(item);
        Node&amp;lt;E&amp;gt; oldHead;
        do {
            oldHead = top.get();
            newHead.next = oldHead;
        } while (!top.compareAndSet(oldHead, newHead));
    }   

    public E pop() {
        Node&amp;lt;E&amp;gt; oldHead;
        Node&amp;lt;E&amp;gt; newHead;
        do {
            oldHead = top.get();
            if (oldHead == null)
                return null;
                newHead = oldHead.next;
        } while (!top.compareAndSet(oldHead, newHead));
        return oldHead.item;
    }

    private static class Node &amp;lt;E&amp;gt; {
        public final E item;
        public Node&amp;lt;E&amp;gt; next;
        public Node(E item) {
            this.item = item;
        }
    }
}
&lt;/pre&gt;


&lt;p&gt;上述算法的top变量是一个性能瓶颈，因为对它的操作无法并发，一种处理方法是将Push和Pop操作互相抵消，以避免对栈的额外操作。[1]&lt;/p&gt;
&lt;p&gt;[1] Lecture on Concurrent Stack in CADS at University of Oxford 2015, https://www.cs.ox.ac.uk/teaching/materials15-16/cads/Lectures/stacks.pdf&lt;/p&gt;
&lt;p&gt;&lt;em&gt;更多关于使用CAS等底层指令来代替锁来实现非阻塞的算法(以后会总结)参见：https://www.cs.ox.ac.uk/teaching/courses/2015-2016/cads/ 和《多处理编程的艺术》第一版修订版&lt;/em&gt;&lt;/p&gt;
&lt;h3&gt;2.5 线程封闭&lt;/h3&gt;
&lt;p&gt;实现线程安全的另一种方法，不共享数据，只在线程内访问数据（不算事同步机制）。当某个对象封闭在一个线程中时，即使对象不是线程安全的，对它的操作也将是线程安全的。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;使用volatile变量本身的可见性，再确保只有一个线程对其进行写入操作，这样就相当于将修改封闭于一个线程中，实现了线程封闭；&lt;/li&gt;
&lt;li&gt;使用局部变量（栈封闭）。因为局部变量本身位于执行线程的栈中，其它线程无法访问。对于基本类型的局部变量，它们始终是线程封闭的；对于引用的对象，需要确保它们不会逸出；&lt;/li&gt;
&lt;li&gt;ThreadLocal类。将某个值与保存值的对象关联起来：每个对象都保存一份该变量的副本，一个线程读写该变量相当于读写它自己的副本。可以将它看做是Map&lt;thread t&gt;，但是实际上各自的副本保存在线程中，线程结束时会被垃圾回收。一般用于防止对可变的singleten变量和全局变量进行共享。使用get和set方法来访问变量。初次调用get方法时，将调用initialValue来初始化值。&lt;/thread&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class="code literal-block"&gt;// 1. 变量定义
private static ThreadLocal&amp;lt;T&amp;gt; localVar = new ThreadLocal&amp;lt;T&amp;gt;{ 
    public T initialValue(){ return someT;}
};
&lt;/pre&gt;


&lt;pre class="code literal-block"&gt;// 2. 变量使用
public static T getT(){ 
    return localVar.get();
}
&lt;/pre&gt;


&lt;h3&gt;2.6 使用（实际上）不可变对象以及安全的发布&lt;/h3&gt;
&lt;p&gt;不可变对象一定是线程安全的。对于多个变量的复合操作的原子性可以通过将它们封装到一个不可变对象中来实现。注意，即使对象的所有域都是final的也可能是可变的，因为final引用的对象可以改变。&lt;/p&gt;
&lt;p&gt;不可变对象：
1. 对象创建以后其状态不能修改；
2. 对象的所有域都是final类型的；
3. 对象是正确创建的，创建期间，this引用没有逸出；&lt;/p&gt;
&lt;p&gt;实际上不可变对象：
1. 从技术上看是可以改变的，但是其状态在发布后不会再改变的对象。&lt;/p&gt;
&lt;p&gt;安全的发布&lt;/p&gt;
&lt;p&gt;对象的引用和状态必须同时对其他线程可见。比如下面就是不安全的发布：&lt;/p&gt;
&lt;pre class="code literal-block"&gt;public Holder holder;
public void initialise(){
    Holder = new Holder(12); 
}
&lt;/pre&gt;


&lt;p&gt;一个正确构造的对象可以通过以下方式安全地发布：
1. 在静态初始化函数中初始化一个对象引用；
2. 将对象引用保存到volatile类型的域或者AtomicReference对象中；
3. 将对象的应用保存到某个正确构造对象的final类型域中；
4. 将对象的引用保存到一个由锁保护的域中。比如将对象放入到一个线程安全的容器中，容器自带内部同步机制。&lt;/p&gt;
&lt;p&gt;不同可变性的对象的发布：
1. 不可变对象可以通过任意机制来发布，即使发布这些对象没有使用同步，任何线程仍可以安全地访问不可变对象并不需要额外的同步措施；
2. 任何线程都可以在没有额外同步机制的情况下，安全地使用被安全发布的实际上不可变对象；
3. 可变对象发布时需要使用同步，并且每次访问都要使用同步机制来保证原子性和可见性。&lt;/p&gt;
&lt;p&gt;线程安全的使用和共享对象的策略
1. 线程封闭
2. 只读共享：指的是不可变对象和实际上不可变对象
3. 线程安全共享：对象内部实现同步机制，通过共有接口来实现访问
4. 保护对象：通过特定的锁来访问的对象。&lt;/p&gt;
&lt;h2&gt;3 并发构建模块与常见模式&lt;/h2&gt;
&lt;h3&gt;3.1 同步容器类&lt;/h3&gt;
&lt;p&gt;早起的同步容器类，比如Vectorhe和Hashtable，都是线程安全的，他们将每个公有方法都进行同步。这种方法将严重降低并发性，并影响吞吐量。&lt;/p&gt;
&lt;p&gt;在这些容器上的复合操作，比如迭代和条件运算，也不需要客户端额外加锁，但是在多个线程并发地修改容器时会出现问题。比如进行“先检查再运算”的getLast和deleteLast可以多线程同时调用，但是一个线程调用getLast一个线程调用deleteLast就可能发生数组越界异常。&lt;/p&gt;
&lt;p&gt;再比如使用这些容器的客户端执行迭代操作时必须加锁（降低并发性），来保证没有ConcurrentModificatrionException。因为一旦其他线程并发的修改容器，那么在迭代期间容器的计数器发生修改，hasNext和next会抛出该异常。这种抛出异常的方式并不一定保证所有并发修改都被检测到，因为这种计数器检查并没有在同步的情况下进行，因此可能会看到失效的值，导致迭代器不会意识到已经发生了修改。&lt;/p&gt;
&lt;p&gt;迭代甚至可能隐式地发生，比如容器的toString方法，hashCode，equals，containsAll，removeAll，retainAll都会隐式地对容器进行迭代，这些隐式迭代器不是线程安全的。&lt;/p&gt;
&lt;p&gt;除了前面说到的加锁，另一种解决办法是克隆容器，并在副本上进行迭代，因为副本封闭在线程内，其他线程不可能同时对其修改，但是克隆会带来显著地性能开销。&lt;/p&gt;
&lt;h3&gt;3.2 并发容器类&lt;/h3&gt;
&lt;h4&gt;3.2.1 ConcurrentHashMap&lt;/h4&gt;
&lt;p&gt;和同步容器不同，ConcurrentHashMap并没有对每一个方法加锁实现同步，而是使用一种粒度更细的锁，称为分段锁(Lock Striping)。&lt;/p&gt;
&lt;p&gt;任意数量的读线程可以并发的访问ConcurrentHashMap，一定数量的写线程可以并发地修改ConcurrentHashMap。迭代器也不会抛出ConcurrentModificatrionException。&lt;/p&gt;
&lt;p&gt;在并发访问环境下它能实现更高地吞吐量，而在单线程环境下只损失很小的性能。只有当应用程序需要加锁Map以进行独占访问时，才应该放弃使用ConcurrentHashMap。&lt;/p&gt;
&lt;h4&gt;3.2.2 ConcurrentSkipListMap  ConcurrentSkipListSet&lt;/h4&gt;
&lt;p&gt;分别作为SortedMap，和SortedSet的并发替代品。&lt;/p&gt;
&lt;h4&gt;3.2.3 CopyOnWriteArrayList和CooyOnWriteArraySet&lt;/h4&gt;
&lt;p&gt;分别用于List和Set的并发替代。每次修改时，都会创建并发布一个新的容器副本，这提供了更好的性能而且迭代器不会抛出ConcurrentModificatrionException。
每次修改容器都会复制底层数组，需要一定的开销，特别是当容器较大的时候。仅当迭代操作远远多于修改操作时，才应该使用CopyOnWrite容器。
Queue and BlockingQueue&lt;/p&gt;
&lt;p&gt;虽然LinkedList可以模拟Queue，事实上也正是LinkedList实现Queue，但是为了去掉List的随机访问方法，增加了Queue类。几种实现包括ConcurrentLinkedQueue和PriorityQueue（非并发）。&lt;/p&gt;
&lt;p&gt;BlockingQueue接口扩展了Queue接口，而且是线程安全的。增加了可阻塞的插入和获取操作。&lt;/p&gt;
&lt;p&gt;[2]关于许多并发容器的实现(以后会总结)参见：https://www.cs.ox.ac.uk/teaching/courses/2015-2016/cads/ 和《多处理编程的艺术》第一版修订版&lt;/p&gt;
&lt;h4&gt;3.2.4 阻塞队列和生产者消费者模式&lt;/h4&gt;
&lt;p&gt;BlockingQueue提供了可阻塞的put和take方法，即当队列满（如果是有界队列）时，put将一直等待直到队列可用，take将在队列空时等待直到队列又元素可取时。也提供了定时的offer和poll方法。队列可以是有界的也可以是无界的。有界队列是一种强大的资源管理工具，可以防止产生过多的工作项。&lt;/p&gt;
&lt;p&gt;阻塞队列支持生产者消费者的设计模式。这种模式将生产数据和消费数据的过程解耦，消除了生产者类和消费者类之间的代码依赖性。生产者把数据放入队列，消费者从队列里获取数据来处理。&lt;/p&gt;
&lt;p&gt;一种常见的生产者消费者设计模式就是线程池和工作队列的组合，比如Executor任务执行框架。&lt;/p&gt;
&lt;p&gt;通过信号量(Semaphore)可以创建其他阻塞数据结构。&lt;/p&gt;
&lt;p&gt;实现包括LinkedBlockingQueue，ArrayBlockingQueue，PriorityBlockingQueue，还有SynchronousQueue。最后的一个并没有维护一个队列的储存空间，而是维护了一组线程，这些线程等待着把元素加入或移除队列。因为它没有储存功能，所以put和take会一直阻塞，直到有另一个线程已经准备好参与到交付过程中。仅当有足够的消费者时，并且总有一个消费者准备好接受工作时，才可以使用SynchronousQueue。&lt;/p&gt;
&lt;p&gt;双端队列Deque和BlockingDeque分别对Queue和Blocking进行扩展。Deque可以在队列头和尾插入和移除。具体实现包括ArrayDeque和LinkedBlokcingDeque。&lt;/p&gt;
&lt;p&gt;Work Stealing是与生产者消费者类似的设计模式。每个消费者有自己的双端队列，如果一个消费者完全了自己的队列，那么它可以从其他消费者的双端队列的末尾中获取工作。这样的设计，不会在一个工作队列上发生竞争，一个线程从另一个线程队列的尾部获取工作时，也降低了对头部获取队列的竞争。&lt;/p&gt;
&lt;p&gt;Work Stealing适合与一个线程既是消费者又是生产者的情况。比如爬虫程序处理一个页面后，会产生更多需要处理的页面，垃圾回收阶段对堆的标记。当一个工作线程找到一个新的任务单元时，会将其放到自己队列的末尾。当自己的双端队列为空时，它会查询其他队列的末尾获取新的任务。&lt;/p&gt;
&lt;p&gt;中断是一种协作机制，线程A中断线程B时，B会在执行到某个可以暂停的地方停止正在执行的操作。BlockingQueue的put和take会抛出InterruptedException，任何抛出该异常的方法是一个阻塞方法，而调用了一个可能抛出该异常的方法时，自己的方法也变成了一个阻塞方法，并且必须要处理对中断的响应：
1. 将该异常继续传递给调用者；
2. 捕获异常，并调用当前线程上的interrupt方法。&lt;/p&gt;
&lt;h3&gt;3.3 同步工具类&lt;/h3&gt;
&lt;p&gt;同步工具类可以是任何一个对象，它们封装了一些状态，能根据自身的状态来协调线程的控制流。像阻塞队列不仅保存工作内容还可以协调控制流，所以它也可以作为同步工具类。另外的同步工具类，包括信号量Semaphore，栅栏Barrier和闭锁Latch。&lt;/p&gt;
&lt;h4&gt;3.3.1 闭锁&lt;/h4&gt;
&lt;p&gt;闭锁等待某些事件全部结束，结束前等待的线程都不能通过；到达结束状态时，闭锁会允许所有线程通过，并且闭锁的状态不会再改变。&lt;/p&gt;
&lt;p&gt;CountDownLatch是一种闭锁的实现。它可以使一个或多个线程等待一组事件的翻身，闭锁状态包括一个计数器，并被初始化为一个正整数，表述需要等待的事件的数量。每发生一个事件，该变量就递减。线程调用await方法等待计数器为0，为0时表示所有事件都已经发生。比如下面这个例子：&lt;/p&gt;
&lt;pre class="code literal-block"&gt;public class TestHarness {
    public long timeTasks(int nThreads, final Runnable task) throws InterruptedException {
        final CountDownLatch startGate = new CountDownLatch(1);
        final CountDownLatch endGate = new CountDownLatch(nThreads);
        for (int i = 0; i &amp;lt; nThreads; i++) {
            Thread t = new Thread() {
                public void run() {
                    try {
                        startGate.await();
                        try {
                            task.run();
                        } finally {
                            endGate.countDown();
                        }
                    } catch (InterruptedException ignored) { }
                }
            };
            t.start();
        }
        long start = System.nanoTime();
        startGate.countDown();
        endGate.await();
        long end = System.nanoTime();
        return end-start;
    }
}
&lt;/pre&gt;


&lt;h4&gt;3.3.2 信号量&lt;/h4&gt;
&lt;p&gt;Semaphore用来控制同时访问某个特定资源的操作数量，可以实现某种资源池，或者对容器施加边界。&lt;/p&gt;
&lt;p&gt;二值信号量是一种特例，就是初始值为1的信号量，可以用做互斥体(mutex)并具备不可重入的加锁寓意。&lt;/p&gt;
&lt;p&gt;当信号量被用作实现资源池时，我们可以构造固定长度的资源池&lt;/p&gt;
&lt;h4&gt;3.3.3 栅栏&lt;/h4&gt;
&lt;p&gt;与闭锁类似，不过闭锁用于等待事件，它用于等待其他线程，只有当所有线程到达Barrier的时候才能继续执行。当线程到达Barrier的时候调用await，线程将等待直到所有线程到达，然后Barrier会打开，所有线程释放，而Barrier会重置。await调用超时会被中断时，栅栏就被打破了，所有等待线程终止等待并抛出BrokenBarrierException。如果成功通过栅栏，每个线程会收到一个返回的唯一的到达索引号。比如模拟程序中需要用到栅栏。&lt;/p&gt;
&lt;p&gt;Exchanger是除了Barrier外的另一种栅栏的形式，它是两方的栅栏，各方在栅栏位置交换数据。当两个线程通过Exchanger交换对象时，这种交换就把两个对象安全的发布给了另一方。&lt;/p&gt;&lt;/div&gt;</description><category>Concurrency</category><category>Java</category><guid>http://www.jiaqili.me/posts/java-concurrency-1/</guid><pubDate>Mon, 28 Dec 2015 07:50:12 GMT</pubDate></item></channel></rss>